{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_set = pd.read_csv(\n",
    "        \"F:\\\\SACHIN\\\\Study\\\\Projects\\\\ML_Data\\\\mnist-digits\\\\train.csv\")\n",
    "    test_set = pd.read_csv(\n",
    "        \"F:\\\\SACHIN\\\\Study\\\\Projects\\\\ML_Data\\\\mnist-digits\\\\test.csv\")\n",
    "\n",
    "    train_set_x = train_set.drop(columns=['label'])\n",
    "    train_set_x_orig = np.array(train_set_x)\n",
    "    train_set_y_orig = np.array(train_set['label'][:])\n",
    "\n",
    "    test_set_x_orig = np.array(test_set)\n",
    "\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(42000,)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, y_train_orig, X_test_orig = load_dataset()\n",
    "\n",
    "print(X_train_orig.shape)\n",
    "print(y_train_orig.shape)\n",
    "print(X_test_orig.shape)\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "    X_train_orig, y_train_orig, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(labels, C):\n",
    "    C = tf.constant(C, name='C')\n",
    "    one_hot_matrix =tf.one_hot(labels, C, axis=0)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    sess.close()\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 37800)\n",
      "(10, 37800)\n",
      "(784, 4200)\n",
      "(10, 4200)\n",
      "(784, 28000)\n"
     ]
    }
   ],
   "source": [
    "y_train = convert_to_one_hot(y_train, 10)\n",
    "\n",
    "y_dev = convert_to_one_hot(y_dev, 10)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], -1).T\n",
    "X_train = X_train / 255\n",
    "\n",
    "X_dev = X_dev.reshape(X_dev.shape[0], -1).T\n",
    "X_dev = X_dev / 255\n",
    "\n",
    "X_test = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "X_test = X_test / 255\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(y_dev.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    X = tf.placeholder(tf.float32, shape=(n_x, None), name='X')\n",
    "    y = tf.placeholder(tf.float32, shape=(n_y, None), name='y')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    W1 = tf.get_variable('W1', [300, 784], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b1 = tf.get_variable('b1', [300, 1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    W2 = tf.get_variable('W2', [200, 300], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable('b2', [200, 1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    W3 = tf.get_variable('W3', [100, 200], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable('b3', [100, 1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    W4 = tf.get_variable('W4', [10, 100], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b4 = tf.get_variable('b4', [10, 1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\n",
    "        'W1': W1,\n",
    "        'b1': b1,\n",
    "        'W2': W2,\n",
    "        'b2': b2,\n",
    "        'W3': W3,\n",
    "        'b3': b3,\n",
    "        'W4': W4,\n",
    "        'b4': b4,\n",
    "    }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, keep_prob):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    drop_out1 = tf.nn.dropout(A1, keep_prob)\n",
    "    \n",
    "    Z2 = tf.add(tf.matmul(W2, drop_out1), b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    \n",
    "    Z4 = tf.add(tf.matmul(W4, A3), b4)\n",
    "    \n",
    "    return Z4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(parameters, Z4, y):\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    W4 = parameters['W4']\n",
    "    \n",
    "    logits = tf.transpose(Z4)\n",
    "    labels = tf.transpose(y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits = logits, labels = labels)\n",
    "                         + 0.001 * tf.nn.l2_loss(W1)\n",
    "                         + 0.001 * tf.nn.l2_loss(W2)\n",
    "                         + 0.001 * tf.nn.l2_loss(W3)\n",
    "                         + 0.001 * tf.nn.l2_loss(W4)) \n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, y, mini_batch_size=32, seed=0):\n",
    "    m =X.shape[1]\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_y = y[:, permutation].reshape((y.shape[0], m))\n",
    "    \n",
    "    num_complete_batches = math.floor(m / mini_batch_size)\n",
    "    \n",
    "    for k in range(0, num_complete_batches) : \n",
    "        mini_batch_X = shuffled_X[:, k*mini_batch_size: \n",
    "                                  k*mini_batch_size + mini_batch_size ]\n",
    "        mini_batch_y = shuffled_y[:, k*mini_batch_size: \n",
    "                                  k*mini_batch_size + mini_batch_size ]\n",
    "        mini_batch = (mini_batch_X, mini_batch_y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_batches * mini_batch_size : m]\n",
    "        mini_batch_y = shuffled_y[:, num_complete_batches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_y)\n",
    "        mini_batches.append(mini_batch)\n",
    "        \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, y_train, learning_rate=0.0001, num_epochs=1500, \n",
    "          minibatch_size = 32, print_cost=True, k_prob=0.5):\n",
    "    ops.reset_default_graph()\n",
    "    (n_x, m) = X_train.shape\n",
    "    n_y = y_train.shape[0]\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    X,y = create_placeholders(n_x, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z4 = forward_propagation(X, parameters, keep_prob)\n",
    "    cost = compute_cost(parameters, Z4, y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    #optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print('Epoch', epoch, 'started...')\n",
    "            epoch_cost = 0\n",
    "            num_minibatches = int(m / minibatch_size)\n",
    "            minibatches = random_mini_batches(X_train, y_train, minibatch_size)\n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_y) = minibatch\n",
    "                _, mini_batch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, y: minibatch_y, keep_prob: k_prob})\n",
    "                epoch_cost += mini_batch_cost / num_minibatches\n",
    "                \n",
    "            if print_cost and epoch % 5 ==0:\n",
    "                print(\"Cost after epoch %i: %f\" %(epoch, epoch_cost))\n",
    "            if print_cost and epoch% 5 == 0 :\n",
    "                costs.append(epoch_cost)\n",
    "                plt.plot(np.squeeze(costs))\n",
    "                \n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "#         plt.title('learning rate:', learning_rate)\n",
    "        plt.show()\n",
    "        \n",
    "        parameters = sess.run(parameters)\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(Z4), tf.argmax(y))\n",
    "        \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "        train_acc = accuracy.eval({X: X_train, y: y_train, keep_prob: 1.0})\n",
    "        test_acc = accuracy.eval({X: X_dev, y: y_dev, keep_prob: 1.0})\n",
    "        print(\"Keep prob: \", k_prob)\n",
    "        print(\"Train accuracy:\", train_acc)\n",
    "        print(\"Test accuracy: \", test_acc)\n",
    "        \n",
    "        print('-----------------------------------------------')\n",
    "        \n",
    "        return parameters, train_acc, test_acc\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started...\n",
      "Cost after epoch 0: 1.178034\n",
      "Epoch 1 started...\n",
      "Epoch 2 started...\n",
      "Epoch 3 started...\n",
      "Epoch 4 started...\n",
      "Epoch 5 started...\n",
      "Cost after epoch 5: 0.445866\n",
      "Epoch 6 started...\n",
      "Epoch 7 started...\n",
      "Epoch 8 started...\n",
      "Epoch 9 started...\n",
      "Epoch 10 started...\n",
      "Cost after epoch 10: 0.338981\n",
      "Epoch 11 started...\n",
      "Epoch 12 started...\n",
      "Epoch 13 started...\n",
      "Epoch 14 started...\n",
      "Epoch 15 started...\n",
      "Cost after epoch 15: 0.283622\n",
      "Epoch 16 started...\n",
      "Epoch 17 started...\n",
      "Epoch 18 started...\n",
      "Epoch 19 started...\n",
      "Epoch 20 started...\n",
      "Cost after epoch 20: 0.246553\n",
      "Epoch 21 started...\n",
      "Epoch 22 started...\n",
      "Epoch 23 started...\n",
      "Epoch 24 started...\n",
      "Epoch 25 started...\n",
      "Cost after epoch 25: 0.219689\n",
      "Epoch 26 started...\n",
      "Epoch 27 started...\n",
      "Epoch 28 started...\n",
      "Epoch 29 started...\n",
      "Epoch 30 started...\n",
      "Cost after epoch 30: 0.201973\n",
      "Epoch 31 started...\n",
      "Epoch 32 started...\n",
      "Epoch 33 started...\n",
      "Epoch 34 started...\n",
      "Epoch 35 started...\n",
      "Cost after epoch 35: 0.188873\n",
      "Epoch 36 started...\n",
      "Epoch 37 started...\n",
      "Epoch 38 started...\n",
      "Epoch 39 started...\n",
      "Epoch 40 started...\n",
      "Cost after epoch 40: 0.178080\n",
      "Epoch 41 started...\n",
      "Epoch 42 started...\n",
      "Epoch 43 started...\n",
      "Epoch 44 started...\n",
      "Epoch 45 started...\n",
      "Cost after epoch 45: 0.172139\n",
      "Epoch 46 started...\n",
      "Epoch 47 started...\n",
      "Epoch 48 started...\n",
      "Epoch 49 started...\n",
      "Epoch 50 started...\n",
      "Cost after epoch 50: 0.168539\n",
      "Epoch 51 started...\n",
      "Epoch 52 started...\n",
      "Epoch 53 started...\n",
      "Epoch 54 started...\n",
      "Epoch 55 started...\n",
      "Cost after epoch 55: 0.163010\n",
      "Epoch 56 started...\n",
      "Epoch 57 started...\n",
      "Epoch 58 started...\n",
      "Epoch 59 started...\n",
      "Epoch 60 started...\n",
      "Cost after epoch 60: 0.160947\n",
      "Epoch 61 started...\n",
      "Epoch 62 started...\n",
      "Epoch 63 started...\n",
      "Epoch 64 started...\n",
      "Epoch 65 started...\n",
      "Cost after epoch 65: 0.157476\n",
      "Epoch 66 started...\n",
      "Epoch 67 started...\n",
      "Epoch 68 started...\n",
      "Epoch 69 started...\n",
      "Epoch 70 started...\n",
      "Cost after epoch 70: 0.155102\n",
      "Epoch 71 started...\n",
      "Epoch 72 started...\n",
      "Epoch 73 started...\n",
      "Epoch 74 started...\n",
      "Epoch 75 started...\n",
      "Cost after epoch 75: 0.152491\n",
      "Epoch 76 started...\n",
      "Epoch 77 started...\n",
      "Epoch 78 started...\n",
      "Epoch 79 started...\n",
      "Epoch 80 started...\n",
      "Cost after epoch 80: 0.151835\n",
      "Epoch 81 started...\n",
      "Epoch 82 started...\n",
      "Epoch 83 started...\n",
      "Epoch 84 started...\n",
      "Epoch 85 started...\n",
      "Cost after epoch 85: 0.150411\n",
      "Epoch 86 started...\n",
      "Epoch 87 started...\n",
      "Epoch 88 started...\n",
      "Epoch 89 started...\n",
      "Epoch 90 started...\n",
      "Cost after epoch 90: 0.150434\n",
      "Epoch 91 started...\n",
      "Epoch 92 started...\n",
      "Epoch 93 started...\n",
      "Epoch 94 started...\n",
      "Epoch 95 started...\n",
      "Cost after epoch 95: 0.147975\n",
      "Epoch 96 started...\n",
      "Epoch 97 started...\n",
      "Epoch 98 started...\n",
      "Epoch 99 started...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2db00daeeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep prob:  0.4\n",
      "Train accuracy: 0.996032\n",
      "Test accuracy:  0.977619\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "parameters, train_accuracy, test_accuracy = model(X_train, y_train, num_epochs=100, k_prob=0.4, print_cost=True)\n",
    "import pickle\n",
    "pickle.dump( parameters, open( \"parameters.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_for_predict(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    \n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    \n",
    "    Z4 = tf.add(tf.matmul(W4, A3), b4)\n",
    "    \n",
    "    return Z4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    W1 = tf.convert_to_tensor(parameters['W1'])\n",
    "    b1 = tf.convert_to_tensor(parameters['b1'])\n",
    "    \n",
    "    W2 = tf.convert_to_tensor(parameters['W2'])\n",
    "    b2 = tf.convert_to_tensor(parameters['b2'])\n",
    "\n",
    "    W3 = tf.convert_to_tensor(parameters['W3'])\n",
    "    b3 = tf.convert_to_tensor(parameters['b3'])\n",
    "\n",
    "    W4 = tf.convert_to_tensor(parameters['W4'])\n",
    "    b4 = tf.convert_to_tensor(parameters['b4'])\n",
    "\n",
    "    params = {\n",
    "        'W1': W1,\n",
    "        'b1': b1,\n",
    "        'W2': W2,\n",
    "        'b2': b2,\n",
    "        'W3': W3,\n",
    "        'b3': b3,\n",
    "        'W4': W4,\n",
    "        'b4': b4,\n",
    "    }\n",
    "    \n",
    "    x = tf.placeholder('float', [784, 1])\n",
    "    \n",
    "    Z4 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(Z4)\n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict={x: X})\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My algorithm predicts: y = 2\n",
      "Actual Value is: y = 2\n",
      "My algorithm predicts: y = 3\n",
      "Actual Value is: y = 3\n",
      "My algorithm predicts: y = 5\n",
      "Actual Value is: y = 5\n",
      "My algorithm predicts: y = 8\n",
      "Actual Value is: y = 8\n",
      "My algorithm predicts: y = 4\n",
      "Actual Value is: y = 4\n",
      "My algorithm predicts: y = 9\n",
      "Actual Value is: y = 9\n",
      "My algorithm predicts: y = 9\n",
      "Actual Value is: y = 9\n",
      "My algorithm predicts: y = 0\n",
      "Actual Value is: y = 0\n",
      "My algorithm predicts: y = 0\n",
      "Actual Value is: y = 0\n",
      "My algorithm predicts: y = 9\n",
      "Actual Value is: y = 9\n",
      "My algorithm predicts: y = 9\n",
      "Actual Value is: y = 9\n",
      "My algorithm predicts: y = 1\n",
      "Actual Value is: y = 1\n",
      "My algorithm predicts: y = 6\n",
      "Actual Value is: y = 6\n",
      "My algorithm predicts: y = 4\n",
      "Actual Value is: y = 4\n",
      "My algorithm predicts: y = 9\n",
      "Actual Value is: y = 9\n",
      "My algorithm predicts: y = 2\n",
      "Actual Value is: y = 2\n",
      "My algorithm predicts: y = 6\n",
      "Actual Value is: y = 6\n",
      "My algorithm predicts: y = 9\n",
      "Actual Value is: y = 9\n",
      "My algorithm predicts: y = 7\n",
      "Actual Value is: y = 7\n",
      "My algorithm predicts: y = 3\n",
      "Actual Value is: y = 3\n"
     ]
    }
   ],
   "source": [
    "train_set_verify = pd.read_csv(\n",
    "        \"F:\\\\SACHIN\\\\Study\\\\Projects\\\\ML_Data\\\\mnist-digits\\\\train.csv\")\n",
    "test_set_submit = pd.read_csv(\n",
    "        \"F:\\\\SACHIN\\\\Study\\\\Projects\\\\ML_Data\\\\mnist-digits\\\\test.csv\")\n",
    "\n",
    "random_indices = list(np.random.randint(100, size=20))\n",
    "train_set_tests = []\n",
    "for i in random_indices:\n",
    "    train_set_tests.append(train_set_verify.iloc[i])\n",
    "train_set_tests = [test.drop(['label'], axis=0) for test in train_set_tests]\n",
    "\n",
    "cntr = 0\n",
    "for train_set_test in train_set_tests:\n",
    "    np_train_set_test = np.array(train_set_test)\n",
    "\n",
    "    np_train_set_test = np_train_set_test.reshape(np_train_set_test.shape[0], -1)\n",
    "    np_train_set_test = np_train_set_test/255\n",
    "\n",
    "    np_train_set_test.shape\n",
    "    my_image_prediction = predict(np_train_set_test, parameters)\n",
    "\n",
    "    print(\"My algorithm predicts: y = \" + str(np.squeeze(my_image_prediction)))\n",
    "    print(\"Actual Value is: y = \" + str(train_set_verify.iloc[random_indices[cntr]][0]))\n",
    "    cntr += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
